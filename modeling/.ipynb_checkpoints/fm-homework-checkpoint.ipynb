{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FILE = './credit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SOURCE_FILE, 'r') as file:\n",
    "    data = file.read()\n",
    "    \n",
    "data = data.replace('\"\\n\\n\"', '\\n').replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "**Number of records**: 1000\n",
    "\n",
    "**Input (8) variables**: \n",
    "* `checking_balance`: Categorical - Status of existing checking account in Deutsche Mark (DM): \n",
    "    * `unknown`: 394\n",
    "    * `< 0 DM`: 274\n",
    "    * `1 - 200 DM`: 269\n",
    "    * `> 200 DM`: 63\n",
    "* `savings_balance`: Categorical - Savings account/bonds in Deutsche Mark (DM):\n",
    "    * `unknown`: 183\n",
    "    * `< 100 DM`: 603\n",
    "    * `101 - 500 DM`: 103\n",
    "    * `501 - 1000 DM`: 63\n",
    "    * `> 1000 DM`: 48\n",
    "* `installment_rate`: Numerical - Installment rate in percentage of disposable income.\n",
    "* `personal_status`: Categorical - Personal status and sex: \n",
    "    * `female`: 310\n",
    "    * `single male`: 548\n",
    "    * `married male`: 92\n",
    "    * `divorced male`: 50\n",
    "* `residence_history`: Numerical - Present residence since\n",
    "* `installment_plan`: Categorical - Other installment plans:\n",
    "    * `none`: 814\n",
    "    * `bank`: 139\n",
    "    * `stores`: 47\n",
    "* `existing_credits`: Numerical - Number of existing credits at this bank\n",
    "* `dependents`: Numerical - Number of people the debtor is required to provide for\n",
    "\n",
    "**Target**:\n",
    "* `default`: Categorical - Credit default:\n",
    "    * `1`: Debtor paid back its loan\n",
    "    * `2`: Debtor defaulted on its loan\n",
    "    \n",
    "**Problem type**: Classification\n",
    "    * **Imbalanced dataset**: Yes and moderate. 700 `1`s vs 300 `2`s.\n",
    "**Missing values**: No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['checking_balance', 'savings_balance', 'installment_rate', \n",
    "           'personal_status', 'residence_history', 'installment_plan', \n",
    "           'existing_credits', 'dependents']\n",
    "\n",
    "target = 'default'\n",
    "\n",
    "usecols = input_features + [target]\n",
    "\n",
    "df = pd.read_csv(io.StringIO(data), header=0, usecols=usecols)\n",
    "\n",
    "df[target] = df[target].map({1:0, 2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_balance</th>\n",
       "      <th>savings_balance</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>residence_history</th>\n",
       "      <th>installment_plan</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>default</th>\n",
       "      <th>dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>single male</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 - 200 DM</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>2</td>\n",
       "      <td>single male</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>2</td>\n",
       "      <td>single male</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>3</td>\n",
       "      <td>single male</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_balance savings_balance  installment_rate personal_status  \\\n",
       "0           < 0 DM         unknown                 4     single male   \n",
       "1       1 - 200 DM        < 100 DM                 2          female   \n",
       "2          unknown        < 100 DM                 2     single male   \n",
       "3           < 0 DM        < 100 DM                 2     single male   \n",
       "4           < 0 DM        < 100 DM                 3     single male   \n",
       "\n",
       "   residence_history installment_plan  existing_credits  default  dependents  \n",
       "0                  4             none                 2        0           1  \n",
       "1                  2             none                 1        1           1  \n",
       "2                  3             none                 1        0           2  \n",
       "3                  4             none                 1        0           2  \n",
       "4                  4             none                 2        1           2  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_VARIABLES = ['checking_balance', 'savings_balance', \n",
    "           'personal_status', 'installment_plan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "import sklearn.model_selection as sk_ms\n",
    "\n",
    "X, y = df[input_features], df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk_ms.train_test_split(X, y, \n",
    "                                                          test_size=TEST_SIZE, \n",
    "                                                         random_state=SEED,\n",
    "                                                         shuffle=True,\n",
    "                                                         stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, criterion='gini',\n",
    "                                   class_weight='balanced', random_state=SEED, \n",
    "                                    max_depth=None, min_samples_leaf=5)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), CATEGORICAL_VARIABLES)\n",
    "    ])\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = sk_ms.StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         OneHotEncoder(categories='auto',\n",
       "                                                                                       drop=None,\n",
       "                                                                                       dtype=<class 'numpy.float64'>,\n",
       "                                                                                       handle_unknown='error'...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'classifier__max_depth': [3, 4, 5, 6, 7],\n",
       "                         'classifier__min_samples_leaf': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7],\n",
    "    'classifier__min_samples_leaf': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_searcher = sk_ms.GridSearchCV(estimator=model, \n",
    "                                   param_grid=param_grid, \n",
    "                                   scoring='f1',\n",
    "                                   cv=cross_validator)\n",
    "\n",
    "grid_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmodel = grid_searcher.best_estimator_\n",
    "metrics.f1_score(y_test, bmodel.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[input_features+[target]].to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 7, 'classifier__min_samples_leaf': 3}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5725780143753122"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.compose\n",
    "\n",
    "sklearn.compose.ColumnTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics\n",
      "--------------------\n",
      "Precision: 0.490 (0.011)\n",
      "Recall: 0.803 (0.014)\n",
      "F1-score: 0.608 (0.010)\n",
      "PR curve AUC: 0.567 (0.024)\n",
      "\n",
      "\n",
      "Validation set metrics\n",
      "--------------------\n",
      "Precision: 0.455 (0.026)\n",
      "Recall: 0.757 (0.049)\n",
      "F1-score: 0.568 (0.034)\n",
      "PR curve AUC: 0.458 (0.047)\n"
     ]
    }
   ],
   "source": [
    "train_precision_scores = []\n",
    "test_precision_scores = []\n",
    "train_recall_scores = []\n",
    "test_recall_scores = []\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []\n",
    "train_pr_curve_auc = []\n",
    "test_pr_curve_auc = []\n",
    "for train_index, test_index in cross_validator.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_precision_scores.append(metrics.precision_score(y_train, y_train_pred))\n",
    "    test_precision_scores.append(metrics.precision_score(y_test, y_test_pred))\n",
    "    train_recall_scores.append(metrics.recall_score(y_train, y_train_pred))\n",
    "    test_recall_scores.append(metrics.recall_score(y_test, y_test_pred))\n",
    "    train_f1_scores.append(metrics.f1_score(y_train, y_train_pred))\n",
    "    test_f1_scores.append(metrics.f1_score(y_test, y_test_pred))\n",
    "    \n",
    "    y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "    y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    train_pre, train_rec, _ = metrics.precision_recall_curve(y_train, y_train_proba) \n",
    "    test_pre, test_rec, _ = metrics.precision_recall_curve(y_test, y_test_proba) \n",
    "    \n",
    "    train_pr_curve_auc.append(metrics.auc(train_rec, train_pre))\n",
    "    test_pr_curve_auc.append(metrics.auc(test_rec, test_pre))\n",
    "    \n",
    "print('Training set metrics')\n",
    "print('--------------------')\n",
    "print('Precision: {:04.3f} ({:04.3f})'.format(np.mean(train_precision_scores), np.std(train_precision_scores)))\n",
    "print('Recall: {:04.3f} ({:04.3f})'.format(np.mean(train_recall_scores), np.std(train_recall_scores)))\n",
    "print('F1-score: {:04.3f} ({:04.3f})'.format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print('PR curve AUC: {:04.3f} ({:04.3f})'.format(np.mean(train_pr_curve_auc), np.std(train_pr_curve_auc)))\n",
    "print('\\n')\n",
    "print('Validation set metrics')\n",
    "print('--------------------')\n",
    "print('Precision: {:04.3f} ({:04.3f})'.format(np.mean(test_precision_scores), np.std(test_precision_scores)))\n",
    "print('Recall: {:04.3f} ({:04.3f})'.format(np.mean(test_recall_scores), np.std(test_recall_scores)))\n",
    "print('F1-score: {:04.3f} ({:04.3f})'.format(np.mean(test_f1_scores), np.std(test_f1_scores)))\n",
    "print('PR curve AUC: {:04.3f} ({:04.3f})'.format(np.mean(test_pr_curve_auc), np.std(test_pr_curve_auc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Script that splits the input data file into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 9)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INPUT_FILE_PATH = './data.csv'\n",
    "OUTPUT_DIR_PATH = '.'\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "INPUT_FEATURES = ['checking_balance', 'savings_balance', 'installment_rate', \n",
    "           'personal_status', 'residence_history', 'installment_plan', \n",
    "           'existing_credits', 'dependents']\n",
    "TARGET = 'default'\n",
    "\n",
    "input_data = pd.read_csv(INPUT_FILE_PATH, \n",
    "                         header=0, \n",
    "                         usecols=[*INPUT_FEATURES, TARGET])\n",
    "\n",
    "datasets = train_test_split(input_data, \n",
    "                            test_size=TEST_SIZE, \n",
    "                            random_state=SEED,\n",
    "                            shuffle=True,\n",
    "                            stratify=input_data[TARGET])\n",
    "\n",
    "output_paths = [os.path.join(OUTPUT_DIR_PATH, filename) \n",
    "                for filename in ('train.csv', 'test.csv')]\n",
    "\n",
    "for dataset, output_path in zip(datasets, output_paths):\n",
    "    dataset.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Script that splits the input data file into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "EXPERIMENT_ID = 'CDEFAULT_RF'\n",
    "INPUT_FILE_PATH = './train.csv'\n",
    "OUTPUT_DIR_PATH = '.'\n",
    "SEED = 42\n",
    "\n",
    "NUMERICAL_FEATURES = ['residence_history', 'installment_rate',  \n",
    "           'existing_credits', 'dependents']\n",
    "\n",
    "CATEGORICAL_FEATURES = ['checking_balance', 'savings_balance', \n",
    "           'personal_status', 'installment_plan']\n",
    "\n",
    "TARGET = 'default'\n",
    "\n",
    "usecols = [*NUMERICAL_FEATURES, *CATEGORICAL_FEATURES, TARGET]\n",
    "input_data = pd.read_csv(INPUT_FILE_PATH, \n",
    "                         header=0, \n",
    "                         usecols=usecols)\n",
    "\n",
    "input_data[TARGET] = input_data[TARGET].map({1:0, 2:1})\n",
    "\n",
    "input_features = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "X, y = input_data[input_features], input_data[TARGET]\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, \n",
    "                                    criterion='gini',\n",
    "                                    class_weight='balanced',\n",
    "                                    random_state=SEED, \n",
    "                                    max_depth=3, \n",
    "                                    min_samples_leaf=7)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), CATEGORICAL_FEATURES)\n",
    "    ])\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', classifier)])\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "current_timestamp = dt.datetime.strftime(dt.datetime.now(), '%Y%m%d%H%M%S')\n",
    "file_name = '_'.join([EXPERIMENT_ID, current_timestamp])\n",
    "joblib.dump(model, os.path.join(OUTPUT_DIR_PATH, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200502172716'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "TRAIN_FILE_PATH = './train.csv'\n",
    "TEST_FILE_PATH = './train.csv'\n",
    "MODEL_FILE_PATH = 'model.joblib'\n",
    "OUTPUT_DIR_PATH = '.'\n",
    "\n",
    "INPUT_FEATURES = ['residence_history', 'installment_rate', 'existing_credits', \n",
    "                  'dependents', 'checking_balance', 'savings_balance', \n",
    "                  'personal_status', 'installment_plan']\n",
    "TARGET = 'default'\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILE_PATH, \n",
    "                        header=0, \n",
    "                        usecols=[*INPUT_FEATURES, TARGET])\n",
    "\n",
    "test_data = pd.read_csv(TEST_FILE_PATH, \n",
    "                        header=0, \n",
    "                        usecols=[*INPUT_FEATURES, TARGET])\n",
    "\n",
    "trained_model = joblib.load(MODEL_FILE_PATH)\n",
    "\n",
    "X_train = train_data[INPUT_FEATURES]\n",
    "X_test = test_data[INPUT_FEATURES]\n",
    "y_train = train_data[TARGET].map({1:0, 2:1})\n",
    "y_test = test_data[TARGET].map({1:0, 2:1})\n",
    "\n",
    "y_train_pred = trained_model.predict(X_train)\n",
    "y_test_pred = trained_model.predict(X_test)\n",
    "    \n",
    "train_precision = metrics.precision_score(y_train, y_train_pred)\n",
    "test_precision = metrics.precision_score(y_test, y_test_pred)\n",
    "train_recall = metrics.recall_score(y_train, y_train_pred)\n",
    "test_recall = metrics.recall_score(y_test, y_test_pred)\n",
    "train_f1 = metrics.f1_score(y_train, y_train_pred)\n",
    "test_f1 = metrics.f1_score(y_test, y_test_pred)\n",
    "\n",
    "y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "train_pre, train_rec, _ = metrics.precision_recall_curve(y_train, y_train_proba) \n",
    "test_pre, test_rec, _ = metrics.precision_recall_curve(y_test, y_test_proba) \n",
    "train_pr_curve_auc = metrics.auc(train_rec, train_pre)\n",
    "test_pr_curve_auc = metrics.auc(test_rec, test_pre)\n",
    "\n",
    "model_name = re.search(pattern=r'(\\w+)\\.joblib', string=MODEL_FILE_PATH).group(1)\n",
    "\n",
    "report_lines = [\n",
    "    'TRAINING REPORT',\n",
    "    'Model: {}'.format(model_name),\n",
    "    '\\n',\n",
    "    'Training set metrics',\n",
    "    '----------------------',\n",
    "    'Precision: {:04.3f}'.format(train_precision),\n",
    "    'Recall: {:04.3f}'.format(train_recall),\n",
    "    'F1-score: {:04.3f}'.format(train_f1),\n",
    "    'PR curve AUC: {:04.3f}'.format(train_pr_curve_auc),\n",
    "    '\\n',\n",
    "    'Test set metrics',\n",
    "    '----------------------',\n",
    "    'Precision: {:04.3f}'.format(test_precision),\n",
    "    'Recall: {:04.3f}'.format(test_recall),\n",
    "    'F1-score: {:04.3f}'.format(test_f1),\n",
    "    'PR curve AUC: {:04.3f}'.format(test_pr_curve_auc)    \n",
    "]\n",
    "\n",
    "file_name = os.path.join(OUTPUT_DIR_PATH, 'training_report_{}.txt'.format(model_name))\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write('\\n'.join(report_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "\n",
    "Technical choices and comments \n",
    "\n",
    "Data and modelling\n",
    "The input dataset consists in 4 categorical variables and 4 numerical variables and 1 target variable.\n",
    "\n",
    "Two categorical variables (`checking_balance` and `savings_balance`) include missing values (labelled `unknown`). These missing values were not imputed nor discarded and were encoded like all the other categories. This choice has been made 1) for simplicity 2) because in our specific use case, a missing value can be information on its own.\n",
    "\n",
    "A next modelling step would consider trying to impute the above-mentionned missing values and/or try to consider the `checking_balance` and `savings_balance` variables not as simple categorical variables but as ordinal variables.\n",
    "\n",
    "Aside from one-hot encoding categorical variables, our preprocessing simply consists in recoding the target variable to better match `sklearn`'s encoding for a target binary variable (`0`/`1` or `-1`/`1`). In particular, numerical variables were not scaled as it was not required by our use of decision trees, nor transformed (ex: log-transformed) as the examination of their distribution show this was not necessary.  \n",
    "\n",
    "We choose a random forest as classifier. Hyperparameter tuning was performed using a grid search (using the F1-score as metric) and a 5-fold stratified cross-validation. As an imbalanced problem (70%/30% class balance) and to avoid creating a majority-class bias, samples were weighted using their class inverse frequency (`class_weight='balanced'`).\n",
    "\n",
    "Notice on chosen metrics \n",
    "As our classification problem is imbalanced:\n",
    "* We choose not to include the accuracy in our metrics\n",
    "* We choose not to use the ROC curve and the associated area-under-curve (AUC) but preferred the Precision/Recall (PR) curve and its AUC.\n",
    "\n",
    "Notice on performance\n",
    "Assessed model performance seems rather mediocre at first sight: 0.XX precision and 0.XX recall. From a business perspective it may not be as bad:\n",
    "* The model avoids to grant a loan to XX% of the bad debtors.\n",
    "* Among all the declined loan submissions however, XX% were actually sound projects.\n",
    "\n",
    "However, we do not know how business values a missed credit opportunity and a default.\n",
    "\n",
    "Next modelling steps would include:\n",
    "* Experimenting with other model specification\n",
    "* Experimenting with model selection metrics that give different weights \n",
    "\n",
    "Simply one hot encoded variables\n",
    "Model spec determined using GridSearch, code not included as not part of requirements\n",
    "Model training understood as not including hyperparameter tuning. Hyperparameter tuning is part of model specification. Reworking model spec is not required as often as retraining. Resource consuming and may require a data scientist.\n",
    "\n",
    "Script 1\n",
    "We choose a stratified split to ensure that the minority class proportion remains the same after the split. \n",
    "\n",
    "The script could be improved by granting the user more flexibility with more command line arguments.\n",
    "\n",
    "Script 2\n",
    "Model training has been understood as not including the hyperparameter tuning (and as not required, the code related to the hyperparameter tuning of our model has not been included). In a perspective of frequent and automatic retrainings, hyperparameter tuning is indeed not included in trainings for two main reasons:\n",
    "* Hyperparameter tuning is costly\n",
    "* Hyperparameter tuning is part of the model specification which should not change with each training (it can but less frequently). Furthermore, as model specification may require the intervention of the data scientist, we may not want to automate it. \n",
    "\n",
    "We can make to suggestions of improvement for this script:\n",
    "* The model specification is currently hard-coded into the script. We could leverage the fact that this specification is included in the model file. Re-training a model could therefore be done by simply using the latest model.\n",
    "* The input feature order is currently hard-coded into the script and it would be better if it were attached to the model as metadata.\n",
    "\n",
    "Script 3\n",
    "We described our choice of metrics further above. This script generated report as a simple text (.txt) file. Including curves or more generally plots would require it to produce a CSV.\n",
    "\n",
    "Include std dev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
